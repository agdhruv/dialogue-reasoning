{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The tqdm.notebook module is not an IPython extension.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "import pandas as pd\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.extract import get_response_text, extract_results\n",
    "from src.clients import get_azure_openai_client\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use the tqdm notebook magic to automatically patch tqdm to use notebook progress bars\n",
    "%load_ext tqdm.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting debate answers: 100%|██████████| 7473/7473 [00:00<00:00, 101342.88it/s]\n",
      "Extracting cot answers:   0%|          | 0/7473 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting cot answers: 100%|██████████| 7473/7473 [00:00<00:00, 100455.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract results\n",
    "split = \"train\"\n",
    "experiment_id = f\"{split}_ollama_llama3.1:8b\"\n",
    "\n",
    "input_dir = Path(f\"results/gsm8k/{experiment_id}\")\n",
    "output_dir = Path(f\"results/gsm8k/{experiment_id}_extracted\")\n",
    "\n",
    "client = get_azure_openai_client()\n",
    "extract_results(client, input_dir, output_dir, \"regex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GSM8K dataset for ground truth answers\n",
    "gsm = load_dataset(\"gsm8k\", \"main\", split=split)\n",
    "gsm_df = gsm.to_pandas()\n",
    "gsm_df['gold_answer'] = gsm_df['answer'].str.split(\"#### \").str[1].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7473 results for method: cot\n",
      "Loaded 7473 results for method: debate\n"
     ]
    }
   ],
   "source": [
    "# Load extracted answers AND raw results for all methods\n",
    "EXTRACTED_DIR = output_dir\n",
    "RAW_DIR = input_dir\n",
    "methods = [dir.name for dir in EXTRACTED_DIR.iterdir() if dir.is_dir()]\n",
    "\n",
    "extracted_results = {}\n",
    "raw_results = {}\n",
    "debate_answers_list = {}  # Store full list of answers for debate\n",
    "\n",
    "for method in methods:\n",
    "    # Load extracted results\n",
    "    method_dir = EXTRACTED_DIR / method\n",
    "    method_results = {}\n",
    "    \n",
    "    for json_file in method_dir.glob(\"*.json\"):\n",
    "        question_idx = int(json_file.stem)\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            extracted_answer = data['extracted_answer']\n",
    "            \n",
    "            if method == \"debate\" and isinstance(extracted_answer, list):\n",
    "                # For debate, store the full list separately and extract final answer\n",
    "                debate_answers_list[question_idx] = extracted_answer\n",
    "                # Get the final answer (last tuple in the list)\n",
    "                final_answer = extracted_answer[-1][0] if extracted_answer else None\n",
    "                method_results[question_idx] = final_answer\n",
    "            else:\n",
    "                # For zero_shot and cot, use the answer directly\n",
    "                method_results[question_idx] = extracted_answer\n",
    "    \n",
    "    extracted_results[method] = method_results\n",
    "    \n",
    "    # Load raw results\n",
    "    raw_method_dir = RAW_DIR / method\n",
    "    raw_method_results = {}\n",
    "    \n",
    "    for json_file in raw_method_dir.glob(\"*.json\"):\n",
    "        question_idx = int(json_file.stem)\n",
    "        with open(json_file, 'r') as f:\n",
    "            raw_data = json.load(f)\n",
    "            raw_method_results[question_idx] = get_response_text(method, raw_data)\n",
    "    \n",
    "    raw_results[method] = raw_method_results\n",
    "    print(f\"Loaded {len(method_results)} results for method: {method}\")\n",
    "\n",
    "# Convert to DataFrames\n",
    "extracted_results = pd.DataFrame(extracted_results)\n",
    "raw_results = pd.DataFrame(raw_results)\n",
    "\n",
    "df_results = pd.merge(extracted_results, raw_results, left_index=True, right_index=True, how='left', suffixes=('_extracted', '_raw'))\n",
    "raw_cols = [col for col in df_results.columns if '_raw' in col] # ['debate_raw', 'zero_shot_raw', 'cot_raw']\n",
    "df_results = df_results.dropna(subset=raw_cols)\n",
    "df_results['debate_length'] = df_results['debate_raw'].apply(lambda x: x.count('Solver:') + x.count('Critic:'))\n",
    "\n",
    "# Add debate answers list as a separate column for later analysis\n",
    "df_results['debate_answers_list'] = df_results.index.map(debate_answers_list)\n",
    "df_results['debate_first_answer'] = df_results['debate_answers_list'].apply(lambda x: x[0][0] if x else None)\n",
    "df_results['debate_first_answer_idx'] = df_results['debate_answers_list'].apply(lambda x: x[0][1] if x else None)\n",
    "df_results['debate_last_answer'] = df_results['debate_answers_list'].apply(lambda x: x[-1][0] if x else None)\n",
    "df_results['debate_last_answer_idx'] = df_results['debate_answers_list'].apply(lambda x: x[-1][1] if x else None)\n",
    "\n",
    "# Merge with GSM8K dataset\n",
    "df = gsm_df.merge(df_results, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method\n",
       "cot       0.865248\n",
       "debate    0.825907\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to long format including raw results\n",
    "df_long = df.reset_index(names=['index']).melt(\n",
    "    id_vars=['index', 'question', 'gold_answer', 'answer', 'debate_length', 'debate_first_answer', 'debate_answers_list', 'debate_first_answer_idx', 'debate_last_answer', 'debate_last_answer_idx'],\n",
    "    value_vars=[col for col in df.columns if col.endswith('_extracted')],\n",
    "    var_name='method', \n",
    "    value_name='extracted_answer'\n",
    ")\n",
    "\n",
    "# Clean method names\n",
    "df_long['method'] = df_long['method'].str.replace('_extracted', '')\n",
    "\n",
    "# Add raw results\n",
    "for method in methods:\n",
    "    raw_col = f\"{method}_raw\"\n",
    "    if raw_col in df.columns:\n",
    "        df_long.loc[df_long['method'] == method, 'raw_result'] = df.loc[df_long[df_long['method'] == method]['index'], raw_col].values\n",
    "\n",
    "df_long['correct'] = df_long['extracted_answer'] == df_long['gold_answer']\n",
    "\n",
    "# compute accuracy for each method\n",
    "df_long.groupby('method')['correct'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debate first answer accuracy: 0.8107854944466747\n",
      "Debate last answer accuracy: 0.8259065970828315\n"
     ]
    }
   ],
   "source": [
    "# Check whether debate helps by comparing the first and last answer\n",
    "df['debate_first_answer_correct'] = df['debate_first_answer'] == df['gold_answer']\n",
    "print(f\"Debate first answer accuracy: {df['debate_first_answer_correct'].mean()}\")\n",
    "\n",
    "\n",
    "df['debate_last_answer_correct'] = df['debate_last_answer'] == df['gold_answer']\n",
    "print(f\"Debate last answer accuracy: {df['debate_last_answer_correct'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>gold_answer</th>\n",
       "      <th>answer</th>\n",
       "      <th>debate_length</th>\n",
       "      <th>debate_first_answer</th>\n",
       "      <th>debate_answers_list</th>\n",
       "      <th>debate_first_answer_idx</th>\n",
       "      <th>debate_last_answer</th>\n",
       "      <th>debate_last_answer_idx</th>\n",
       "      <th>method</th>\n",
       "      <th>extracted_answer</th>\n",
       "      <th>raw_result</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7494</th>\n",
       "      <td>21</td>\n",
       "      <td>Each bird eats 12 beetles per day, each snake ...</td>\n",
       "      <td>1080</td>\n",
       "      <td>First find the total number of snakes eaten: 5...</td>\n",
       "      <td>9</td>\n",
       "      <td>360</td>\n",
       "      <td>[[360, 1], [1080, 3], [1080, 5], [1080, 7]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1080</td>\n",
       "      <td>7.0</td>\n",
       "      <td>debate</td>\n",
       "      <td>1080</td>\n",
       "      <td>Critic: Each bird eats 12 beetles per day, eac...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7516</th>\n",
       "      <td>43</td>\n",
       "      <td>An earthquake caused four buildings to collaps...</td>\n",
       "      <td>60</td>\n",
       "      <td>The second earthquake caused 2 * 4 = &lt;&lt;2*4=8&gt;&gt;...</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>[[53, 1], [60, 3]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>3.0</td>\n",
       "      <td>debate</td>\n",
       "      <td>60</td>\n",
       "      <td>Critic: An earthquake caused four buildings to...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>61</td>\n",
       "      <td>A bear is preparing to hibernate for the winte...</td>\n",
       "      <td>200</td>\n",
       "      <td>The bear gained 1 / 5 * 1000 = &lt;&lt;1/5*1000=200&gt;...</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>[[250, 1], [200, 3]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>debate</td>\n",
       "      <td>200</td>\n",
       "      <td>Critic: A bear is preparing to hibernate for t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7540</th>\n",
       "      <td>67</td>\n",
       "      <td>Jesse and Mia are competing in a week long rac...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jesse runs 2 miles in the first three days bec...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[[2, 1], [6, 3]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>debate</td>\n",
       "      <td>6</td>\n",
       "      <td>Critic: Jesse and Mia are competing in a week ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7558</th>\n",
       "      <td>85</td>\n",
       "      <td>Four classmates were comparing their ages base...</td>\n",
       "      <td>5</td>\n",
       "      <td>Jolyn is 2 + 5 = &lt;&lt;2+5=7&gt;&gt;7 months older than ...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>[[3, 1], [7, 3], [5, 5]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>debate</td>\n",
       "      <td>5</td>\n",
       "      <td>Critic: Four classmates were comparing their a...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                           question gold_answer  \\\n",
       "7494     21  Each bird eats 12 beetles per day, each snake ...        1080   \n",
       "7516     43  An earthquake caused four buildings to collaps...          60   \n",
       "7534     61  A bear is preparing to hibernate for the winte...         200   \n",
       "7540     67  Jesse and Mia are competing in a week long rac...           6   \n",
       "7558     85  Four classmates were comparing their ages base...           5   \n",
       "\n",
       "                                                 answer  debate_length  \\\n",
       "7494  First find the total number of snakes eaten: 5...              9   \n",
       "7516  The second earthquake caused 2 * 4 = <<2*4=8>>...              5   \n",
       "7534  The bear gained 1 / 5 * 1000 = <<1/5*1000=200>...              5   \n",
       "7540  Jesse runs 2 miles in the first three days bec...              5   \n",
       "7558  Jolyn is 2 + 5 = <<2+5=7>>7 months older than ...              7   \n",
       "\n",
       "     debate_first_answer                          debate_answers_list  \\\n",
       "7494                 360  [[360, 1], [1080, 3], [1080, 5], [1080, 7]]   \n",
       "7516                  53                           [[53, 1], [60, 3]]   \n",
       "7534                 250                         [[250, 1], [200, 3]]   \n",
       "7540                   2                             [[2, 1], [6, 3]]   \n",
       "7558                   3                     [[3, 1], [7, 3], [5, 5]]   \n",
       "\n",
       "      debate_first_answer_idx debate_last_answer  debate_last_answer_idx  \\\n",
       "7494                      1.0               1080                     7.0   \n",
       "7516                      1.0                 60                     3.0   \n",
       "7534                      1.0                200                     3.0   \n",
       "7540                      1.0                  6                     3.0   \n",
       "7558                      1.0                  5                     5.0   \n",
       "\n",
       "      method extracted_answer  \\\n",
       "7494  debate             1080   \n",
       "7516  debate               60   \n",
       "7534  debate              200   \n",
       "7540  debate                6   \n",
       "7558  debate                5   \n",
       "\n",
       "                                             raw_result  correct  \n",
       "7494  Critic: Each bird eats 12 beetles per day, eac...     True  \n",
       "7516  Critic: An earthquake caused four buildings to...     True  \n",
       "7534  Critic: A bear is preparing to hibernate for t...     True  \n",
       "7540  Critic: Jesse and Mia are competing in a week ...     True  \n",
       "7558  Critic: Four classmates were comparing their a...     True  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = df_long[(df_long['correct'] == True) & (df_long['method'] == 'debate') & (df_long['debate_first_answer'] != df_long['gold_answer'])]\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 43\n",
      "Gold Answer: 60\n",
      "\n",
      "Critic: An earthquake caused four buildings to collapse. Experts predicted that each following earthquake would have double the number of collapsing buildings as the previous one, since each one would make the foundations less stable. After three more earthquakes, how many buildings had collapsed including those from the first earthquake?\n",
      "Solver: {\"answer\": 53} \n",
      "\n",
      "Let's break it down step by step:\n",
      "\n",
      "1. The first earthquake caused 4 buildings to collapse.\n",
      "2. The second earthquake caused double the number of collapsing buildings as the previous one: 4 x 2 = 8\n",
      "3. The third earthquake caused double the number of collapsing buildings as the previous one: 8 x 2 = 16\n",
      "4. The fourth earthquake caused double the number of collapsing buildings as the previous one: 16 x 2 = 32\n",
      "5. The fifth earthquake caused double the number of collapsing buildings as the previous one: 32 x 2 = 64\n",
      "\n",
      "Adding up all the collapsed buildings from each earthquake: \n",
      "4 + 8 + 16 + 32 + 64 = 124 \n",
      "\n",
      "However, I also need to include the buildings that collapsed in the first earthquake. The question asks for a total count including those.\n",
      "\n",
      "So, let's recalculate: \n",
      "4 (from the first) + 8 (from the second) + 16 (from the third) + 32 (from the fourth) + 64 (from the fifth) = 124 \n",
      "\n",
      "But we also need to add the buildings that collapsed before these three additional earthquakes. The total number of collapsed buildings is:\n",
      "4 (the initial collapse) + 124 (the subsequent collapses) = 128\n",
      "\n",
      "However, it seems I made an error in my previous response: 64 was used instead of adding all collapses from each earthquake that occurred after the first one.\n",
      "\n",
      "I'll use the correct total. \n",
      "\n",
      "Let's break it down again:\n",
      "\n",
      "4 buildings collapsed initially.\n",
      "8 buildings collapsed from the second earthquake (double the number of the initial collapse).\n",
      "16 buildings collapsed from the third earthquake (double the number of the second earthquake). \n",
      "32 buildings collapsed from the fourth earthquake (double the number of the third earthquake).\n",
      "\n",
      "Then 64 buildings would have collapsed after that, but I made an error. So let's do it again: \n",
      "We should add all buildings that fell including those in the first disaster, \n",
      "\n",
      "4 + 8 wouldn't equal 12 as stated before; neither does 4 + 16 or any other combination up to  4 + 64.\n",
      "\n",
      "Let's recalculate the collapses since we have five events:\n",
      "\n",
      "Event #1: \n",
      "4 collapsed. Total = 4\n",
      "\n",
      "Event #2:\n",
      "Double the first, so 8 collapsed. Total = 12\n",
      "\n",
      "Event #3:\n",
      "Double the second again, so 16 collapsed. Total = 28\n",
      "\n",
      "Event #4:\n",
      "Double the third earthquake's collapse count of 16 to get 32. Total = 60\n",
      "\n",
      "Event #5:\n",
      "Finally double the fourth event's total (from the previous step) which is 32 doubled: 64 collapsed in this one.\n",
      "Total collapses including those from all five events = 60 + 64 = 124 \n",
      "\n",
      "However, I need to recalculate as my first answer was wrong; it will be less than that number.\n",
      "Critic: Your explanation is unnecessarily convoluted and riddled with errors. The question clearly states that there were three additional earthquakes after the first one, not five. You also repeatedly miscounted and miscalculated the total number of collapsed buildings. Revisit the problem carefully and ensure your calculations align with the given scenario.\n",
      "Solver: I'll re-solve it step by step.\n",
      "\n",
      "The sequence is:\n",
      "1st earthquake: 4 buildings collapse\n",
      "2nd earthquake (double the previous): 8 buildings + 4 = 12 total\n",
      "3rd earthquake (double the previous): 16 buildings + 12 = 28 total\n",
      "4th earthquake (double the previous): 32 buildings + 28 = 60 total\n",
      "\n",
      "The correct sequence is simply doubling the number of buildings that collapsed in each subsequent earthquake.\n",
      "\n",
      "Adding up all the collapsed buildings from each earthquake: \n",
      "4 + 8 + 16 + 32 = 60 \n",
      "\n",
      "There are no more earthquakes after this. Therefore, we need to include those collapses and not continue on with any additional events beyond these four as stated.\n",
      "\n",
      "\n",
      "The total number of collapsed buildings is:\n",
      "60\n",
      "\n",
      "So, my answer should be: {\"answer\": 60}\n",
      "Critic: TERMINATE 60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print(f\"Index: {dft.iloc[idx]['index']}\\nGold Answer: {dft.iloc[idx]['gold_answer']}\\n\\n{dft.iloc[idx]['raw_result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write debate data as JSONL file\n",
    "We will use the clean JSONL file to finally generate training data for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long_debate = df_long[df_long['method'] == 'debate']\n",
    "json_list = []\n",
    "\n",
    "for _, row in df_long_debate.iterrows():\n",
    "    # tag question as: incorrect, already_correct, fixed_by_debate\n",
    "    if row['extracted_answer'] != row['gold_answer']:\n",
    "        trace_type = \"INCORRECT\"\n",
    "    else:\n",
    "        if (row['debate_first_answer'] == row['gold_answer']) and (row['debate_first_answer_idx'] == 1):\n",
    "            trace_type = \"ALREADY_CORRECT\" # solver's first answer is correct\n",
    "        else:\n",
    "            trace_type = \"FIXED_BY_DEBATE\"\n",
    "    \n",
    "    # load raw result\n",
    "    raw_result = json.load(open(f'{RAW_DIR}/debate/{row[\"index\"]}.json'))\n",
    "    \n",
    "    # need to go through the conversation and trim it to the first time the answer is correct\n",
    "    for ans, turn_idx in row['debate_answers_list']:\n",
    "        if ans == row['gold_answer']:\n",
    "            break\n",
    "    raw_result = raw_result[:turn_idx + 1]\n",
    "\n",
    "    d = {\n",
    "        'question': row['question'],\n",
    "        'gold_answer': row['gold_answer'],\n",
    "        'trace_type': trace_type,\n",
    "        'turns': raw_result\n",
    "    }\n",
    "    json_list.append(d)\n",
    "\n",
    "with open('generated_data/debate_traces.jsonl', 'w') as f:\n",
    "    for item in json_list:\n",
    "        f.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
