{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e1a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "RESULTS_DIR = Path(\"evaluation_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "511d06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate results\n",
    "results = []\n",
    "for f in os.listdir(RESULTS_DIR):\n",
    "    with open(RESULTS_DIR / f, \"r\") as f:\n",
    "        results.append(json.load(f))\n",
    "        \n",
    "# Save and print results\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83990f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoT accuracy: 0.8051554207733131\n",
      "Finetuned accuracy: 0.8036391205458681\n"
     ]
    }
   ],
   "source": [
    "results_df['cot_correct'] = results_df['cot_answer'] == results_df['gold_answer']\n",
    "results_df['finetuned_correct'] = results_df['finetuned_answer'] == results_df['gold_answer']\n",
    "cot_accuracy = results_df['cot_correct'].mean()\n",
    "finetuned_accuracy = results_df['finetuned_correct'].mean()\n",
    "print(f\"CoT accuracy: {cot_accuracy}\")\n",
    "print(f\"Finetuned accuracy: {finetuned_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5476cea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>gold_answer</th>\n",
       "      <th>cot_output</th>\n",
       "      <th>cot_answer</th>\n",
       "      <th>finetuned_output</th>\n",
       "      <th>finetuned_answer</th>\n",
       "      <th>cot_correct</th>\n",
       "      <th>finetuned_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>For a New Year's resolution, Andy wants to los...</td>\n",
       "      <td>525</td>\n",
       "      <td>To determine the total number of days Andy has...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|begin_of_text|&gt;&lt;|start_head...</td>\n",
       "      <td>523</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Cole wanted to buy new jeans for a dance conte...</td>\n",
       "      <td>8</td>\n",
       "      <td>Step 1: First, let's calculate the original pr...</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|begin_of_text|&gt;&lt;|start_head...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>Each solid 10-foot section of a redwood tree w...</td>\n",
       "      <td>5600</td>\n",
       "      <td>To find the total weight of the redwood, we ne...</td>\n",
       "      <td>5600</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|begin_of_text|&gt;&lt;|start_head...</td>\n",
       "      <td>8000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>I have 10 liters of orange drink that are two-...</td>\n",
       "      <td>15</td>\n",
       "      <td>To find out how much water is in the remaining...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|begin_of_text|&gt;&lt;|start_head...</td>\n",
       "      <td>58</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>James gets 10 new CDs.  Each CD cost $15.  He ...</td>\n",
       "      <td>50</td>\n",
       "      <td>To find the total amount James spent on the CD...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|begin_of_text|&gt;&lt;|start_head...</td>\n",
       "      <td>110</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>Manny signed up for Karate classes for $60. Hi...</td>\n",
       "      <td>4</td>\n",
       "      <td>Let's break it down step by step:\\n\\n1. The to...</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|begin_of_text|&gt;&lt;|start_head...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>Juan and his brother Carlos are selling lemona...</td>\n",
       "      <td>15</td>\n",
       "      <td>To solve this problem, we need to follow these...</td>\n",
       "      <td>15</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|begin_of_text|&gt;&lt;|start_head...</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>A custodian has to clean a school with 80 clas...</td>\n",
       "      <td>50</td>\n",
       "      <td>To find the total number of classrooms that ne...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|begin_of_text|&gt;&lt;|start_head...</td>\n",
       "      <td>90</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>I am three years younger than my brother, and ...</td>\n",
       "      <td>13</td>\n",
       "      <td>To solve this problem, let's break it down ste...</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|begin_of_text|&gt;&lt;|start_head...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>John brings his dog to the vet. His dog needs ...</td>\n",
       "      <td>25</td>\n",
       "      <td>To find out how much John leaves with, we need...</td>\n",
       "      <td>25</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|begin_of_text|&gt;&lt;|start_head...</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>Last month, Tasha made $80 from selling lemona...</td>\n",
       "      <td>26</td>\n",
       "      <td>Step 1: Let's denote the number of times Tasha...</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|begin_of_text|&gt;&lt;|start_head...</td>\n",
       "      <td>74</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question gold_answer  \\\n",
       "54    For a New Year's resolution, Andy wants to los...         525   \n",
       "371   Cole wanted to buy new jeans for a dance conte...           8   \n",
       "471   Each solid 10-foot section of a redwood tree w...        5600   \n",
       "481   I have 10 liters of orange drink that are two-...          15   \n",
       "492   James gets 10 new CDs.  Each CD cost $15.  He ...          50   \n",
       "733   Manny signed up for Karate classes for $60. Hi...           4   \n",
       "738   Juan and his brother Carlos are selling lemona...          15   \n",
       "813   A custodian has to clean a school with 80 clas...          50   \n",
       "980   I am three years younger than my brother, and ...          13   \n",
       "1119  John brings his dog to the vet. His dog needs ...          25   \n",
       "1280  Last month, Tasha made $80 from selling lemona...          26   \n",
       "\n",
       "                                             cot_output cot_answer  \\\n",
       "54    To determine the total number of days Andy has...       None   \n",
       "371   Step 1: First, let's calculate the original pr...          4   \n",
       "471   To find the total weight of the redwood, we ne...       5600   \n",
       "481   To find out how much water is in the remaining...       None   \n",
       "492   To find the total amount James spent on the CD...       None   \n",
       "733   Let's break it down step by step:\\n\\n1. The to...          9   \n",
       "738   To solve this problem, we need to follow these...         15   \n",
       "813   To find the total number of classrooms that ne...       None   \n",
       "980   To solve this problem, let's break it down ste...         13   \n",
       "1119  To find out how much John leaves with, we need...         25   \n",
       "1280  Step 1: Let's denote the number of times Tasha...         32   \n",
       "\n",
       "                                       finetuned_output finetuned_answer  \\\n",
       "54    <|begin_of_text|><|begin_of_text|><|start_head...              523   \n",
       "371   <|begin_of_text|><|begin_of_text|><|start_head...             None   \n",
       "471   <|begin_of_text|><|begin_of_text|><|start_head...             8000   \n",
       "481   <|begin_of_text|><|begin_of_text|><|start_head...               58   \n",
       "492   <|begin_of_text|><|begin_of_text|><|start_head...              110   \n",
       "733   <|begin_of_text|><|begin_of_text|><|start_head...                1   \n",
       "738   <|begin_of_text|><|begin_of_text|><|start_head...                6   \n",
       "813   <|begin_of_text|><|begin_of_text|><|start_head...               90   \n",
       "980   <|begin_of_text|><|begin_of_text|><|start_head...             None   \n",
       "1119  <|begin_of_text|><|begin_of_text|><|start_head...               25   \n",
       "1280  <|begin_of_text|><|begin_of_text|><|start_head...               74   \n",
       "\n",
       "      cot_correct  finetuned_correct  \n",
       "54          False              False  \n",
       "371         False              False  \n",
       "471          True              False  \n",
       "481         False              False  \n",
       "492         False              False  \n",
       "733         False              False  \n",
       "738          True              False  \n",
       "813         False              False  \n",
       "980          True              False  \n",
       "1119         True               True  \n",
       "1280        False              False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see rows where critic was invoked\n",
    "dfc = results_df[results_df['finetuned_output'].str.contains('<|endofturn|><|critic|>', regex=False)]\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b74f432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a debate assistant. Respond with alternating segments that start with <|solver|> or <|critic|> and finish each turn with <|endofturn|>. Use no other tags.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "<|question|> James gets 10 new CDs.  Each CD cost $15.  He gets them for 40% off.  He decides he doesn't like 5 of them and sells them for 40. How much money was he out?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "<|solver|> To find out how much James spent on the CDs, we need to calculate the original price and then subtract the discount.\n",
      "\n",
      "Original price: 10 CDs x $15/CD = $150\n",
      "Discount: 40% of $150 = 0.4 x $150 = $60\n",
      "Price after discount: $150 - $60 = $90\n",
      "\n",
      "James sold 5 CDs for $40 each, so he got a total of:\n",
      "5 CDs x $40/CD = $200\n",
      "\n",
      "Now, let's calculate how much money James was out:\n",
      "\n",
      "Total amount spent: $90 (on the CDs) + $200 (the price he got from selling 5 CDs) = $290\n",
      "However, we need to subtract the original price of those 5 CDs that he sold, which is:\n",
      "5 CDs x $15/CD = $75\n",
      "\n",
      "So, the correct calculation is:\n",
      "Total amount spent: $90 + ($200 - $75) = $90 + $125 = $215\n",
      "\n",
      "Therefore, James was out by: \n",
      "$215 - (the original price of all CDs) = $150 (original price) - $215 = -$65 \n",
      "But since you can't be negative out, I will recalculate.\n",
      "\n",
      "The total amount he got from selling the CDs is $200 and he sold them for 40% off. So the original price of those CDs was:\n",
      "$200 / (1 - 0.4) = $200 / 0.6 = $333.33\n",
      "\n",
      "Now, let's calculate how much money James was out:\n",
      "\n",
      "Total amount spent on CDs: $90\n",
      "Original price of all CDs: 10 CDs x $15/CD = $150\n",
      "He also got some money from selling the CDs: $333.33 (original price) - $200 (price he sold them for) = $133.33\n",
      "\n",
      "So, the correct calculation is:\n",
      "Total amount James was out: ($90 - $75) + ($150 - $90) + ($133.33 - $200) = $15 + $60 - $66.67 = $8.33 \n",
      "\n",
      "{\"answer\": 8.33}<|endofturn|><|critic|> Your calculations are convoluted and contain multiple errors. Let’s break this down step by step:\n",
      "\n",
      "1. James buys 10 CDs at $15 each, so the total cost is **10 × $15 = $150**.\n",
      "2. He gets a 40% discount on the total cost, which is **0.4 × $150 = $60**. The discounted price is **$150 - $60 = $90**.\n",
      "3. James decides to sell 5 of the CDs for $40 each, so he earns **5 × $40 = $200**.\n",
      "4. The question asks how much money James was \"out,\" which means we need to compare his expenditure ($90) to his earnings ($200). Since his earnings exceed his expenditure, James is not actually \"out\" any money. Instead, he has a profit of **$200 - $90 = $110**.\n",
      "\n",
      "Your final answer of $8.33 is incorrect because it implies that James has lost money, which contradicts the fact that he sold the CDs for more than he paid. Revisit your assumptions and calculations.<|endofturn|><|solver|> You are correct in breaking down the problem step by step, and I appreciate you pointing out the errors in my previous response.\n",
      "\n",
      "To correct my understanding:\n",
      "\n",
      "1. James buys 10 CDs at $15 each, so the total cost is **10 × $15 = $150**.\n",
      "2. He gets a 40% discount on the total cost, which is **0.4 × $150 = $60**. The discounted price is **$150 - $60 = $90**.\n",
      "3. James decides to sell 5 of the CDs for $40 each, so he earns **5 × $40 = $200**.\n",
      "4. To find out how much money James was \"out,\" we need to compare his expenditure ($90) to his earnings ($200). Since his earnings exceed his expenditure, James has a profit of **$200 - $90 = $110**.\n",
      "\n",
      "Therefore, the correct answer is:\n",
      "\n",
      "{\"answer\": 110}<|endofturn|><|endofdialogue|>\n"
     ]
    }
   ],
   "source": [
    "s = dfc['finetuned_output'].iloc[4]\n",
    "segs = s[s.find('<|solver|>', s.find('<|solver|>') + 1):].split('<|endofturn|>')[:-1]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9490273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "ADAPTER_DIR = Path(\"lora_debate_ckpts\") / \"checkpoint-600\"  # last SFT ckpt\n",
    "BASE_MODEL = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "def load_finetuned_model():\n",
    "    \"\"\"Load base model + LoRA adapters\"\"\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        BASE_MODEL, torch_dtype=torch.bfloat16, device_map=\"auto\"\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ADAPTER_DIR)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model = PeftModel.from_pretrained(model, ADAPTER_DIR)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6507f4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:25<00:00,  6.40s/it]\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 14.57 GiB of which 1.31 GiB is free. Including non-PyTorch memory, this process has 13.26 GiB memory in use. Of the allocated memory 11.92 GiB is allocated by PyTorch, and 1.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mload_finetuned_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mload_finetuned_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     13\u001b[39m tokenizer = AutoTokenizer.from_pretrained(ADAPTER_DIR)\n\u001b[32m     14\u001b[39m model.resize_token_embeddings(\u001b[38;5;28mlen\u001b[39m(tokenizer))\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m model = \u001b[43mPeftModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mADAPTER_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/dialogue-reasoning/.venv/lib/python3.13/site-packages/peft/peft_model.py:555\u001b[39m, in \u001b[36mPeftModel.from_pretrained\u001b[39m\u001b[34m(cls, model, model_id, adapter_name, is_trainable, config, autocast_adapter_dtype, ephemeral_gpu_offload, low_cpu_mem_usage, key_mapping, **kwargs)\u001b[39m\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    547\u001b[39m     model = MODEL_TYPE_TO_PEFT_MODEL_MAPPING[config.task_type](\n\u001b[32m    548\u001b[39m         model,\n\u001b[32m    549\u001b[39m         config,\n\u001b[32m   (...)\u001b[39m\u001b[32m    552\u001b[39m         low_cpu_mem_usage=low_cpu_mem_usage,\n\u001b[32m    553\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m555\u001b[39m load_result = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_adapter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m    \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_trainable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_trainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[43mautocast_adapter_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautocast_adapter_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[38;5;66;03m# 1. Remove VB-LoRA vector bank, since it's a shared parameter set via the VBLoRAModel\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;66;03m# 2. Remove the prompt encoder, as it does not need to be part of the checkpoint\u001b[39;00m\n\u001b[32m    567\u001b[39m missing_keys = [\n\u001b[32m    568\u001b[39m     k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m load_result.missing_keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvblora_vector_bank\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m k \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mprompt_encoder\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m k\n\u001b[32m    569\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/dialogue-reasoning/.venv/lib/python3.13/site-packages/peft/peft_model.py:1317\u001b[39m, in \u001b[36mPeftModel.load_adapter\u001b[39m\u001b[34m(self, model_id, adapter_name, is_trainable, torch_device, autocast_adapter_dtype, ephemeral_gpu_offload, low_cpu_mem_usage, key_mapping, **kwargs)\u001b[39m\n\u001b[32m   1314\u001b[39m     peft_config.inference_mode = \u001b[38;5;129;01mnot\u001b[39;00m is_trainable\n\u001b[32m   1315\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_adapter(adapter_name, peft_config, low_cpu_mem_usage=low_cpu_mem_usage)\n\u001b[32m-> \u001b[39m\u001b[32m1317\u001b[39m adapters_weights = \u001b[43mload_peft_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1318\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhf_hub_download_kwargs\u001b[49m\n\u001b[32m   1319\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1321\u001b[39m \u001b[38;5;66;03m# load the weights into the model\u001b[39;00m\n\u001b[32m   1322\u001b[39m ignore_mismatched_sizes = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mignore_mismatched_sizes\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/dialogue-reasoning/.venv/lib/python3.13/site-packages/peft/utils/save_and_load.py:583\u001b[39m, in \u001b[36mload_peft_weights\u001b[39m\u001b[34m(model_id, device, key_mapping, **hf_hub_download_kwargs)\u001b[39m\n\u001b[32m    581\u001b[39m         adapters_weights = safe_load_file(filename, device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    582\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m         adapters_weights = \u001b[43msafe_load_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    585\u001b[39m     adapters_weights = torch_load(filename, map_location=torch.device(device))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/dialogue-reasoning/.venv/lib/python3.13/site-packages/safetensors/torch.py:315\u001b[39m, in \u001b[36mload_file\u001b[39m\u001b[34m(filename, device)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m safe_open(filename, framework=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, device=device) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m f.keys():\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m         result[k] = \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 14.57 GiB of which 1.31 GiB is free. Including non-PyTorch memory, this process has 13.26 GiB memory in use. Of the allocated memory 11.92 GiB is allocated by PyTorch, and 1.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "model = load_finetuned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc746fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
